{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`data_preprocessed_cut_2_Valence.csv`と`data_preprocessed_cut_2_Arousal.csv`のmodelをimportしてpredをcsv出力する\n",
    "相関係数rを出す"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/matplotlib/__init__.py:1067: UserWarning: Duplicate key in file \"/home/ubuntu/.config/matplotlib/matplotlibrc\", line #2\n",
      "  (fname, cnt))\n",
      "/home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/matplotlib/__init__.py:1067: UserWarning: Duplicate key in file \"/home/ubuntu/.config/matplotlib/matplotlibrc\", line #3\n",
      "  (fname, cnt))\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import gensim\n",
    "gensim_model = gensim.models.KeyedVectors.load_word2vec_format('./word2vec/data.bin', binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = gensim_model.vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300 3000000\n"
     ]
    }
   ],
   "source": [
    "embedding_dim = weights.shape[1]\n",
    "print(embedding_dim,weights.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = np.append(weights,np.zeros((1,embedding_dim)),axis=0)\n",
    "# 末尾にunknown_wordを追加"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3000001\n"
     ]
    }
   ],
   "source": [
    "vocab_size = weights.shape[0]\n",
    "print(vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_size = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "cuda = torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# wordのindexを取得\n",
    "# print(gensim_model.wv.vocab['always'].index)\n",
    "# 100番目のwordを取得\n",
    "# print(gensim_model.wv.index2word[100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_sequence(seq):\n",
    "    vocab = gensim_model.wv.vocab\n",
    "    idxs = [vocab[w].index if w in vocab else vocab_size - 1 for w in seq]\n",
    "    res = torch.tensor(idxs, dtype=torch.long)\n",
    "    if cuda:\n",
    "        res = res.cuda()\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentence2vec(sentence):\n",
    "    w_list = sentence.split()\n",
    "    res_seq = prepare_sequence(w_list)\n",
    "    return res_seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# s = \"I'm always fucking you.\"\n",
    "# sentence2vec(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMTagger(nn.Module):\n",
    "    def __init__(self, embedding_dim, hidden_dim, vocab_size, tagset_size):\n",
    "        super(LSTMTagger, self).__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "\n",
    "        self.word_embeddings = nn.Embedding(vocab_size, embedding_dim)\n",
    "\n",
    "        # The LSTM takes word embeddings as inputs, and outputs hidden states\n",
    "        # with dimensionality hidden_dim.\n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, batch_first=True)\n",
    "\n",
    "        # The linear layer that maps from hidden state space to tag space\n",
    "        self.out = nn.Linear(hidden_dim, tagset_size)\n",
    "        self.hidden = self.init_hidden(1)\n",
    "\n",
    "    def init_hidden(self,batch_size):\n",
    "        # Before we've done anything, we dont have any hidden state.\n",
    "        # Refer to the Pytorch documentation to see exactly\n",
    "        # why they have this dimensionality.\n",
    "        # The axes semantics are (num_layers, minibatch_size, hidden_dim)\n",
    "        h = torch.zeros(1, batch_size, self.hidden_dim)\n",
    "        c = torch.zeros(1, batch_size, self.hidden_dim)\n",
    "        if cuda:\n",
    "            h = h.cuda()\n",
    "            c = c.cuda()\n",
    "        return (h,c)\n",
    "\n",
    "    def forward(self, sentence, lengths):\n",
    "        embeds = self.word_embeddings(sentence)\n",
    "#         print(embeds.size())\n",
    "#         batch_size = embeds.size()[0]\n",
    "        packed = nn.utils.rnn.pack_padded_sequence(embeds,lengths,batch_first=True)\n",
    "        lstm_output, self.hidden = self.lstm(packed, self.hidden)\n",
    "        unpacked,_ = nn.utils.rnn.pad_packed_sequence(lstm_output,batch_first=True)\n",
    "        # batch * hidden \n",
    "        output = self.out(unpacked[:,-1,:])\n",
    "        output = F.tanh(output)\n",
    "        return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.state_dict().keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_model(hidden_dim):\n",
    "    # 学習済みパラメータ\n",
    "    torch.manual_seed(1)\n",
    "    model = LSTMTagger(embedding_dim, hidden_dim, vocab_size, out_size)\n",
    "    model.word_embeddings = nn.Embedding.from_pretrained(torch.from_numpy(weights).float())\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(model,model_name):\n",
    "    model_state_dict = model.state_dict()\n",
    "    model_state_dict.pop('word_embeddings.weight')\n",
    "    torch.save(model_state_dict,model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(hidden_dim,model_name):\n",
    "    torch.manual_seed(1)\n",
    "    model = LSTMTagger(embedding_dim, hidden_dim, vocab_size, out_size)\n",
    "    model_state_dict = torch.load(model_name)\n",
    "    model_state_dict['word_embeddings.weight'] = torch.from_numpy(weights).float()\n",
    "    model.load_state_dict(model_state_dict)\n",
    "    # Freeze\n",
    "    model.word_embeddings.weight.requires_grad = False\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vad_type='Valence'\n",
    "# data_cut = pd.read_csv('./data_preprocessed_{0}.csv'.format(vad_type),encoding='utf-16')\n",
    "# data_cut = data_cut[data_cut['words']>=2]\n",
    "# X_train = data_cut[data_cut['data_type']=='train']['reg'].as_matrix()\n",
    "# Y_train = data_cut[data_cut['data_type']=='train'][['{0}_reg'.format(vad_type)]].as_matrix()\n",
    "# samples = []\n",
    "# for sentence,target in zip(X_train,Y_train):\n",
    "#     sentence_vec = sentence2vec(sentence)\n",
    "#     y_hat = torch.tensor(target, dtype=torch.float)\n",
    "#     if cuda:\n",
    "#         y_hat = y_hat.cuda()\n",
    "#     samples.append((sentence_vec,y_hat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_tensor(vec, pad, dim):\n",
    "    \"\"\"\n",
    "    args:\n",
    "        vec - tensor to pad\n",
    "        pad - the size to pad to\n",
    "        dim - dimension to pad\n",
    "\n",
    "    return:\n",
    "        a new tensor padded to 'pad' in dimension 'dim'\n",
    "    \"\"\"\n",
    "    pad_size = list(vec.shape)\n",
    "    pad_size[dim] = pad - vec.size(dim)\n",
    "    res = torch.cat([vec, (torch.zeros(*pad_size,dtype=torch.long).cuda() \\\n",
    "                           if cuda else torch.zeros(*pad_size,dtype=torch.long))], dim=dim)\n",
    "    if cuda:\n",
    "        res = res.cuda()\n",
    "    return res\n",
    "\n",
    "class PadCollate:\n",
    "    \"\"\"\n",
    "    a variant of callate_fn that pads according to the longest sequence in\n",
    "    a batch of sequences\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, dim=0):\n",
    "        \"\"\"\n",
    "        args:\n",
    "            dim - the dimension to be padded (dimension of time in sequences)\n",
    "        \"\"\"\n",
    "        self.dim = dim\n",
    "\n",
    "    def pad_collate(self, batch):\n",
    "        \"\"\"\n",
    "        args:\n",
    "            batch - list of (tensor, label)\n",
    "\n",
    "        reutrn:\n",
    "            xs - a tensor of all examples in 'batch' after padding\n",
    "            ys - a LongTensor of all labels in batch\n",
    "        \"\"\"\n",
    "        lengths = list(map(lambda x: x[0].shape[self.dim], batch))\n",
    "        # find longest sequence\n",
    "        max_len = max(lengths)\n",
    "        # pad according to max_len\n",
    "        xs = torch.zeros([len(lengths),max_len],dtype=torch.long)\n",
    "        if cuda:\n",
    "            xs = xs.cuda()\n",
    "        for idx,(seq,seqlen) in enumerate(zip(batch,lengths)):\n",
    "            xs[idx,:seqlen] = seq[0]\n",
    "        ys = torch.FloatTensor(list(map(lambda x: x[1], batch)))\n",
    "        lengths_tensor = torch.tensor(lengths)\n",
    "\n",
    "        if cuda:\n",
    "            xs = xs.cuda()\n",
    "            ys = ys.cuda()\n",
    "            lengths_tensor = lengths_tensor.cuda()\n",
    "        return xs, ys, lengths_tensor\n",
    "\n",
    "    def __call__(self, batch):\n",
    "        return self.pad_collate(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_loader = DataLoader(samples,batch_size=4,shuffle=True,collate_fn=PadCollate(dim=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for sam in train_loader:\n",
    "#     sam\n",
    "#     print(sam[0].size(),sam[1].size())\n",
    "#     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_dataset(X,Y):\n",
    "    ds = []\n",
    "    for sentence,target in zip(X,Y):\n",
    "        sentence_vec = sentence2vec(sentence)\n",
    "        y_hat = torch.tensor(target, dtype=torch.float)\n",
    "        if cuda:\n",
    "            y_hat = y_hat.cuda()\n",
    "        ds.append((sentence_vec,y_hat))\n",
    "    return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_pred(hidden_dim,vad_type,model_name,dat_base_name='./data_preprocessed'):\n",
    "    # args\n",
    "    # dat_base_name : _{Valence,Arousal}.csv以前へのパス\n",
    "    # save_dor : modelとjsonをsaveするdir (中にjson,modelディレクトリを含む)\n",
    "\n",
    "    #     json_name = '{0}/json/loss_{1}_hidden_dim_{2}_batch_{3}_lr_{4}.json'.format(\\\n",
    "    #                    save_dir,vad_type,hidden_dim,batch_size,learning_rate)\n",
    "\n",
    "    model = load_model(hidden_dim,model_name)\n",
    "\n",
    "    if cuda:\n",
    "        model.cuda()\n",
    "\n",
    "    data_cut = pd.read_csv('{0}_{1}.csv'.format(dat_base_name,vad_type),encoding='utf-16')\n",
    "    data_cut = data_cut[data_cut['words']>=2]\n",
    "\n",
    "    X_train = data_cut[data_cut['data_type']=='train']['reg'].as_matrix()\n",
    "    X_dev   = data_cut[data_cut['data_type']=='dev']['reg'].as_matrix()\n",
    "    X_test  = data_cut[data_cut['data_type']=='test']['reg'].as_matrix()\n",
    "    Y_train = data_cut[data_cut['data_type']=='train'][['{0}_reg'.format(vad_type)]].as_matrix()\n",
    "    Y_dev   = data_cut[data_cut['data_type']=='dev'][['{0}_reg'.format(vad_type)]].as_matrix()\n",
    "    Y_test  = data_cut[data_cut['data_type']=='test'][['{0}_reg'.format(vad_type)]].as_matrix()\n",
    "\n",
    "    loader = {}\n",
    "    \n",
    "    batch_size = 1\n",
    "    \n",
    "    ds_train = make_dataset(X_train,Y_train)\n",
    "    loader['train'] = DataLoader(ds_train,batch_size=batch_size,shuffle=False,collate_fn=PadCollate(dim=0))\n",
    "\n",
    "    ds_dev = make_dataset(X_dev,Y_dev)\n",
    "    loader['dev'] = DataLoader(ds_dev,batch_size=batch_size,shuffle=False,collate_fn=PadCollate(dim=0))\n",
    "    \n",
    "    ds_test = make_dataset(X_test,Y_test)\n",
    "    loader['test'] = DataLoader(ds_test,batch_size=batch_size,shuffle=False,collate_fn=PadCollate(dim=0))\n",
    "    \n",
    "\n",
    "    lis = ['train','dev','test']\n",
    "    \n",
    "    y_true = {}\n",
    "    y_pred = {}\n",
    "    \n",
    "    for data_type in lis:\n",
    "        y_true[data_type] = []\n",
    "        y_pred[data_type] = []\n",
    "        for x_batch,y_batch,lengths in loader[data_type]:\n",
    "            model.zero_grad()\n",
    "            model.hidden = model.init_hidden(len(x_batch))\n",
    "\n",
    "            # sort\n",
    "            lengths, perm_idx = lengths.sort(0, descending=True)\n",
    "            x_batch = x_batch[perm_idx]\n",
    "            y_batch = y_batch[perm_idx]\n",
    "            y_true[data_type].append(y_batch.cpu().detach().numpy()[0])\n",
    "\n",
    "            y_p = model(x_batch,lengths)\n",
    "            y_p = y_p.view(-1)\n",
    "            y_pred[data_type].append(y_p.cpu().detach().numpy()[0])\n",
    "    \n",
    "    return y_true,y_pred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/ipykernel/__main__.py:2: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    }
   ],
   "source": [
    "save_dir='./dat_model_json/dat_word_cut_l1loss'\n",
    "hidden_dim = 128\n",
    "vad_type = 'Valence'\n",
    "batch_size = 4\n",
    "learning_rate = 0.001\n",
    "epoch = 50\n",
    "model_name = '{0}/model/model_{1}_hidden_dim_{2}_batch_{3}_lr_{4}_epoch_{5}'.format(\\\n",
    "                        save_dir,vad_type,hidden_dim,batch_size,learning_rate,epoch)\n",
    "\n",
    "y_true_v, y_pred_v = make_pred(hidden_dim,vad_type,model_name,dat_base_name='./data_preprocessed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train : 0.7211203020973606\n",
      "dev : 0.6813731184931702\n",
      "test : 0.6714589264296188\n"
     ]
    }
   ],
   "source": [
    "data_types = ['train','dev','test' ]\n",
    "for data_type in data_types:\n",
    "    print(\"{0} : {1}\".format(data_type,np.corrcoef(y_true_v[data_type],y_pred_v[data_type])[0,1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/ipykernel/__main__.py:2: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    }
   ],
   "source": [
    "save_dir='./dat_model_json/dat_word_cut_l1loss'\n",
    "hidden_dim = 64\n",
    "vad_type = 'Arousal'\n",
    "batch_size = 4\n",
    "learning_rate = 0.001\n",
    "epoch = 50\n",
    "model_name = '{0}/model/model_{1}_hidden_dim_{2}_batch_{3}_lr_{4}_epoch_{5}'.format(\\\n",
    "                        save_dir,vad_type,hidden_dim,batch_size,learning_rate,epoch)\n",
    "\n",
    "y_true_a, y_pred_a = make_pred(hidden_dim,vad_type,model_name,dat_base_name='./data_preprocessed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train : 0.4822053015506005\n",
      "dev : 0.5122123707767103\n",
      "test : 0.4766804936908686\n"
     ]
    }
   ],
   "source": [
    "data_types = ['train','dev','test' ]\n",
    "for data_type in data_types:\n",
    "    print(\"{0} : {1}\".format(data_type,np.corrcoef(y_true_a[data_type],y_pred_a[data_type])[0,1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_pytorch_p36)",
   "language": "python",
   "name": "conda_pytorch_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
