{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting gensim\n",
      "  Downloading https://files.pythonhosted.org/packages/86/f3/37504f07651330ddfdefa631ca5246974a60d0908216539efda842fd080f/gensim-3.5.0-cp36-cp36m-manylinux1_x86_64.whl (23.5MB)\n",
      "Requirement already satisfied: numpy>=1.11.3 in /home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from gensim) (1.14.2)\n",
      "Requirement already satisfied: scipy>=0.18.1 in /home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from gensim) (1.1.0)\n",
      "Requirement already satisfied: six>=1.5.0 in /home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from gensim) (1.11.0)\n",
      "Collecting smart-open>=1.2.1 (from gensim)\n",
      "  Downloading https://files.pythonhosted.org/packages/cf/3d/5f3a9a296d0ba8e00e263a8dee76762076b9eb5ddc254ccaa834651c8d65/smart_open-1.6.0.tar.gz\n",
      "Collecting boto>=2.32 (from smart-open>=1.2.1->gensim)\n",
      "  Downloading https://files.pythonhosted.org/packages/bd/b7/a88a67002b1185ed9a8e8a6ef15266728c2361fcb4f1d02ea331e4c7741d/boto-2.48.0-py2.py3-none-any.whl (1.4MB)\n",
      "Collecting bz2file (from smart-open>=1.2.1->gensim)\n",
      "  Downloading https://files.pythonhosted.org/packages/61/39/122222b5e85cd41c391b68a99ee296584b2a2d1d233e7ee32b4532384f2d/bz2file-0.98.tar.gz\n",
      "Requirement already satisfied: requests in /home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from smart-open>=1.2.1->gensim) (2.18.4)\n",
      "Requirement already satisfied: boto3 in /home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from smart-open>=1.2.1->gensim) (1.7.8)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from requests->smart-open>=1.2.1->gensim) (3.0.4)\n",
      "Requirement already satisfied: idna<2.7,>=2.5 in /home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from requests->smart-open>=1.2.1->gensim) (2.6)\n",
      "Requirement already satisfied: urllib3<1.23,>=1.21.1 in /home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from requests->smart-open>=1.2.1->gensim) (1.22)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from requests->smart-open>=1.2.1->gensim) (2018.4.16)\n",
      "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from boto3->smart-open>=1.2.1->gensim) (0.9.3)\n",
      "Requirement already satisfied: botocore<1.11.0,>=1.10.8 in /home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from boto3->smart-open>=1.2.1->gensim) (1.10.8)\n",
      "Requirement already satisfied: s3transfer<0.2.0,>=0.1.10 in /home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from boto3->smart-open>=1.2.1->gensim) (0.1.13)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1; python_version >= \"2.7\" in /home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from botocore<1.11.0,>=1.10.8->boto3->smart-open>=1.2.1->gensim) (2.7.2)\n",
      "Requirement already satisfied: docutils>=0.10 in /home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from botocore<1.11.0,>=1.10.8->boto3->smart-open>=1.2.1->gensim) (0.14)\n",
      "Building wheels for collected packages: smart-open, bz2file\n",
      "  Running setup.py bdist_wheel for smart-open: started\n",
      "  Running setup.py bdist_wheel for smart-open: finished with status 'done'\n",
      "  Stored in directory: /home/ubuntu/.cache/pip/wheels/73/f1/9b/ccf93d4ba073b6f79b1ed9df68ab5ce048d8136d0efcf90b30\n",
      "  Running setup.py bdist_wheel for bz2file: started\n",
      "  Running setup.py bdist_wheel for bz2file: finished with status 'done'\n",
      "  Stored in directory: /home/ubuntu/.cache/pip/wheels/81/75/d6/e1317bf09bf1af5a30befc2a007869fa6e1f516b8f7c591cb9\n",
      "Successfully built smart-open bz2file\n",
      "Installing collected packages: boto, bz2file, smart-open, gensim\n",
      "Successfully installed boto-2.48.0 bz2file-0.98 gensim-3.5.0 smart-open-1.6.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "mkl-random 1.0.1 requires cython, which is not installed.\n",
      "mkl-fft 1.0.0 requires cython, which is not installed.\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "pip install gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "\n",
    "torch.manual_seed(1)\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "from nltk.corpus import wordnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import gensim\n",
    "gensim_model = gensim.models.KeyedVectors.load_word2vec_format('./data.bin', binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/ipykernel/__main__.py:1: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n",
      "  if __name__ == '__main__':\n",
      "/home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/ipykernel/__main__.py:1: DeprecationWarning: Call to deprecated `syn0` (Attribute will be removed in 4.0.0, use self.wv.vectors instead).\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(3000000, 300)"
      ]
     },
     "execution_count": 276,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights = gensim_model.wv.syn0\n",
    "weights.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = weights.shape[0]\n",
    "embedding_dim = weights.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = np.append(weights,np.zeros((1,embedding_dim)),axis=0)\n",
    "# 末尾にunknown_wordを追加"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = weights.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "609\n",
      "company\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/ipykernel/__main__.py:2: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n",
      "  from ipykernel import kernelapp as app\n",
      "/home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/ipykernel/__main__.py:4: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n"
     ]
    }
   ],
   "source": [
    "# wordのindexを取得\n",
    "print(gensim_model.wv.vocab[\"'d\"].index)\n",
    "# 100番目のwordを取得\n",
    "print(gensim_model.wv.index2word[100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import nltk\n",
    "from nltk import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_sequence(seq):\n",
    "    vocab = gensim_model.wv.vocab\n",
    "    idxs = [vocab[w].index if w in vocab else vocab_size - 1 for w in seq]\n",
    "    return torch.tensor(idxs, dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentence2vec(sentence,debug=False):\n",
    "    w_list = word_tokenize(sentence)\n",
    "    w_list = [wordnet.morphy(w) if wordnet.morphy(w) is not None else w for w in w_list]\n",
    "    if debug:\n",
    "        print(w_list)\n",
    "    res_seq = prepare_sequence(w_list)\n",
    "    return res_seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['I', \"'m\", 'always', 'fucking', 'dog', '.']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/ipykernel/__main__.py:2: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([ 2.0000e+01,  2.3600e+02,  3.8800e+02,  2.7891e+04,  2.0430e+03,\n",
       "         3.0000e+06])"
      ]
     },
     "execution_count": 359,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = \"I'm always fucking dogs.\"\n",
    "sentence2vec(s,debug=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMTagger(nn.Module):\n",
    "\n",
    "    def __init__(self, embedding_dim, hidden_dim, vocab_size, tagset_size):\n",
    "        super(LSTMTagger, self).__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "\n",
    "        self.word_embeddings = nn.Embedding(vocab_size, embedding_dim)\n",
    "\n",
    "        # The LSTM takes word embeddings as inputs, and outputs hidden states\n",
    "        # with dimensionality hidden_dim.\n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_dim)\n",
    "\n",
    "        # The linear layer that maps from hidden state space to tag space\n",
    "        self.out = nn.Linear(hidden_dim, tagset_size)\n",
    "        self.hidden = self.init_hidden()\n",
    "\n",
    "    def init_hidden(self):\n",
    "        # Before we've done anything, we dont have any hidden state.\n",
    "        # Refer to the Pytorch documentation to see exactly\n",
    "        # why they have this dimensionality.\n",
    "        # The axes semantics are (num_layers, minibatch_size, hidden_dim)\n",
    "        h = torch.zeros(1, 1, self.hidden_dim)\n",
    "        c = torch.zeros(1, 1, self.hidden_dim)\n",
    "#         if cuda:\n",
    "#             h = h.cuda()\n",
    "#             c = c.cuda()\n",
    "        return (h,c)\n",
    "\n",
    "    def forward(self, sentence):\n",
    "        embeds = self.word_embeddings(sentence)\n",
    "#         print(embeds.size())\n",
    "        \n",
    "        lstm_output, self.hidden = self.lstm(\n",
    "            embeds.view(len(sentence),1,-1), self.hidden)\n",
    "        \n",
    "        output = self.out(lstm_output.view(len(sentence),-1))\n",
    "        output = F.tanh(output)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_dim = 6\n",
    "out_size = 3\n",
    "model = LSTMTagger(embedding_dim, hidden_dim, vocab_size, out_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 学習済みパラメータ\n",
    "model.word_embeddings = nn.Embedding.from_pretrained(torch.from_numpy(weights).float())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_function = nn.MSELoss()\n",
    "optimizer = optim.SGD(filter(lambda p: p.requires_grad, model.parameters()), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0.1828, -0.0878,  0.2294])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/ipykernel/__main__.py:2: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    }
   ],
   "source": [
    "sample = [\n",
    "    \"I'm always fucking you hey\",\n",
    "    \"oh my godness\"\n",
    "] \n",
    "\n",
    "# forwardのsample\n",
    "with torch.no_grad():\n",
    "    inputs = sentence2vec(sample[0])\n",
    "    output = model(inputs)\n",
    "    print(output[-1,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataのload\n",
    "data_pre = pd.read_csv('./data_preprocessed.csv')\n",
    "\n",
    "# 2word以上のsentence\n",
    "data_pre = data_pre[data_pre['words']>=2]\n",
    "\n",
    "X_orig = data_pre['reg'].as_matrix()\n",
    "Y_v = data_pre['Valence'].as_matrix()\n",
    "Y_a = data_pre['Arousal'].as_matrix()\n",
    "Y_d = data_pre['Dominance'].as_matrix()\n",
    "Y_orig = np.c_[Y_v,Y_a,Y_d]\n",
    "a=1\n",
    "b=5\n",
    "Y_orig = (2*(Y_orig-a)/(b-a))-1\n",
    "# [-1,1]で正規化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X_orig\n",
    "Y = Y_orig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = 0.7\n",
    "dev_size = 0.2\n",
    "X_train, X_rest, Y_train, Y_rest = train_test_split(X, Y, test_size=1-train_size)\n",
    "X_dev, X_test, Y_dev, Y_test = train_test_split(X_rest,Y_rest,test_size=1-(train_size+dev_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/ipykernel/__main__.py:2: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n",
      "  from ipykernel import kernelapp as app\n",
      "/home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/ipykernel/__main__.py:27: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0: loss 0.03251407551398661\n",
      "epoch 1: loss 0.03148706812360908\n"
     ]
    }
   ],
   "source": [
    "epochs = 30\n",
    "\n",
    "loss_ary = []\n",
    "\n",
    "for epoch in range(epochs):  # again, normally you would NOT do 300 epochs, it is toy data\n",
    "    loss_sum = 0\n",
    "    X_train,Y_train = shuffle(X_train,Y_train)\n",
    "    for sentence, target in zip(X_train,Y_train):\n",
    "        # Step 1. Remember that Pytorch accumulates gradients.\n",
    "        # We need to clear them out before each instance\n",
    "        model.zero_grad()\n",
    "\n",
    "        # Also, we need to clear out the hidden state of the LSTM,\n",
    "        # detaching it from its history on the last instance.\n",
    "        model.hidden = model.init_hidden()\n",
    "\n",
    "        # Step 2. Get our inputs ready for the network, that is, turn them into\n",
    "        # Tensors of word indices.\n",
    "        sentence_in = sentence2vec(sentence)\n",
    "        \n",
    "        # Step 3. Run our forward pass.\n",
    "        y = model(sentence_in)[-1,:]\n",
    "\n",
    "        # Step 4. Compute the loss, gradients, and update the parameters by\n",
    "        #  calling optimizer.step()\n",
    "        loss = loss_function(y, torch.tensor(target, dtype=torch.float))\n",
    "        loss_sum += loss.data[0].item()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    print(\"epoch {0}: loss {1}\".format(epoch,loss_sum/len(X_train)))\n",
    "    loss_ary.append(loss_sum/len(X_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['to compare his pieces to those of others is to compare mannequins to living models ',\n",
       "       '“nathan ” said nepthys  “i think that you just did something very stupid ”',\n",
       "       'today our unique network of 0 huts and lodges—each a day’s hike apart—stretches 0 miles through the white mountain national forest ',\n",
       "       ...,\n",
       "       'wholesalers compete against each other    perhaps you forgot ',\n",
       "       \"more than a toy  it's an equalizer that allows poor kids to ride with rich \",\n",
       "       'there are also demonstrations of traditional chinese crafts  including silk-weaving  pottery  and p apermaking '],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 368,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_pytorch_p36)",
   "language": "python",
   "name": "conda_pytorch_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
