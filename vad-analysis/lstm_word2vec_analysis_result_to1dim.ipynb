{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/matplotlib/__init__.py:1067: UserWarning: Duplicate key in file \"/home/ubuntu/.config/matplotlib/matplotlibrc\", line #2\n",
      "  (fname, cnt))\n",
      "/home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/matplotlib/__init__.py:1067: UserWarning: Duplicate key in file \"/home/ubuntu/.config/matplotlib/matplotlibrc\", line #3\n",
      "  (fname, cnt))\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "\n",
    "torch.manual_seed(1)\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "from nltk.corpus import wordnet\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import gensim\n",
    "gensim_model = gensim.models.KeyedVectors.load_word2vec_format('./word2vec/data.bin', binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/ipykernel/__main__.py:1: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n",
      "  if __name__ == '__main__':\n",
      "/home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/ipykernel/__main__.py:1: DeprecationWarning: Call to deprecated `syn0` (Attribute will be removed in 4.0.0, use self.wv.vectors instead).\n",
      "  if __name__ == '__main__':\n"
     ]
    }
   ],
   "source": [
    "weights = gensim_model.wv.syn0\n",
    "# weights.shape\n",
    "embedding_dim = weights.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = np.append(weights,np.zeros((1,embedding_dim)),axis=0)\n",
    "# 末尾にunknown_wordを追加"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = weights.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "cuda = torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_size = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMTagger(nn.Module):\n",
    "    \n",
    "    def __init__(self, embedding_dim, hidden_dim, vocab_size, tagset_size):\n",
    "        super(LSTMTagger, self).__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "\n",
    "        self.word_embeddings = nn.Embedding(vocab_size, embedding_dim)\n",
    "\n",
    "        # The LSTM takes word embeddings as inputs, and outputs hidden states\n",
    "        # with dimensionality hidden_dim.\n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_dim)\n",
    "\n",
    "        # The linear layer that maps from hidden state space to tag space\n",
    "        self.out = nn.Linear(hidden_dim, tagset_size)\n",
    "        self.hidden = self.init_hidden()\n",
    "\n",
    "    def init_hidden(self):\n",
    "        # Before we've done anything, we dont have any hidden state.\n",
    "        # Refer to the Pytorch documentation to see exactly\n",
    "        # why they have this dimensionality.\n",
    "        # The axes semantics are (num_layers, minibatch_size, hidden_dim)\n",
    "        h = torch.zeros(1, 1, self.hidden_dim)\n",
    "        c = torch.zeros(1, 1, self.hidden_dim)\n",
    "        if cuda:\n",
    "            h = h.cuda()\n",
    "            c = c.cuda()\n",
    "        return (h,c)\n",
    "\n",
    "    def forward(self, sentence):\n",
    "        embeds = self.word_embeddings(sentence)\n",
    "#         print(embeds.size())\n",
    "\n",
    "        lstm_output, self.hidden = self.lstm(\n",
    "            embeds.view(len(sentence),1,-1), self.hidden)\n",
    "\n",
    "        output = self.out(lstm_output.view(len(sentence),-1))\n",
    "        output = F.tanh(output)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import nltk\n",
    "from nltk import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_sequence(seq):\n",
    "    vocab = gensim_model.wv.vocab\n",
    "    idxs = [vocab[w].index if w in vocab else vocab_size - 1 for w in seq]\n",
    "    res = torch.tensor(idxs, dtype=torch.long)\n",
    "    if cuda:\n",
    "        res = res.cuda()\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentence2vec(sentence,debug=False):\n",
    "    sentence = sentence.replace(\"'\",\" \").replace(\".\",\" \").replace(\",\",\" \").replace(\"\\\"\",\" \")\n",
    "    w_list = word_tokenize(sentence)\n",
    "    w_list = [wordnet.morphy(w).lower() if wordnet.morphy(w) is not None else w.lower() for w in w_list]\n",
    "    if debug:\n",
    "        print(w_list)\n",
    "    res_seq = prepare_sequence(w_list)\n",
    "    return res_seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(hidden_dim,model_name):\n",
    "    torch.manual_seed(1)\n",
    "    model = LSTMTagger(embedding_dim, hidden_dim, vocab_size, out_size)\n",
    "    model_state_dict = torch.load(model_name)\n",
    "    model_state_dict['word_embeddings.weight'] = torch.from_numpy(weights).float()\n",
    "    model.load_state_dict(model_state_dict)\n",
    "    model.word_embeddings.weight.requires_grad = False\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_prediction(hidden_dim,model_path,dat_csv):\n",
    "    model = load_model(hidden_dim, model_path)\n",
    "    if cuda:\n",
    "        model.cuda()\n",
    "\n",
    "    data_cut = pd.read_csv(dat_csv,encoding='utf-16')\n",
    "    data_cut = data_cut[data_cut['words']>=2]\n",
    "    pred_list = []\n",
    "    for index,row in data_cut.iterrows():\n",
    "        sentence = row['sentence']\n",
    "        model.zero_grad()\n",
    "        model.hidden = model.init_hidden()\n",
    "        sentence_in = sentence2vec(sentence)\n",
    "        y = model(sentence_in)[-1,:]\n",
    "        if cuda:\n",
    "            y = y.cpu()\n",
    "        pred_list.append(y.detach().numpy())\n",
    "\n",
    "    pred_list = np.array(pred_list)\n",
    "\n",
    "    pred_list = pred_list*2 + 3\n",
    "\n",
    "    return pred_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_dim = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/ipykernel/__main__.py:2: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    }
   ],
   "source": [
    "model_v_path = './dat_to1/model_Valence_hidden_dim_8_epoch_50'\n",
    "csv_v_path = './data_preprocessed_Valence.csv'\n",
    "v_ary = make_prediction(hidden_dim,model_v_path,csv_v_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>id</th>\n",
       "      <th>sentence</th>\n",
       "      <th>Arousal</th>\n",
       "      <th>Dominance</th>\n",
       "      <th>Valence</th>\n",
       "      <th>sd.Arousal</th>\n",
       "      <th>sd.Dominance</th>\n",
       "      <th>sd.Valence</th>\n",
       "      <th>freq</th>\n",
       "      <th>reg</th>\n",
       "      <th>words</th>\n",
       "      <th>data_type</th>\n",
       "      <th>Valence_reg</th>\n",
       "      <th>Arousal_reg</th>\n",
       "      <th>Dominance_reg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2568</td>\n",
       "      <td>cable_spool_fort_5107_5146</td>\n",
       "      <td>Several more boys spewed out after him.</td>\n",
       "      <td>3.2</td>\n",
       "      <td>2.6</td>\n",
       "      <td>2.6</td>\n",
       "      <td>0.748331</td>\n",
       "      <td>0.489898</td>\n",
       "      <td>0.489898</td>\n",
       "      <td>5</td>\n",
       "      <td>several more boys spewed out after him</td>\n",
       "      <td>7</td>\n",
       "      <td>train</td>\n",
       "      <td>-0.2</td>\n",
       "      <td>0.1</td>\n",
       "      <td>-0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2548</td>\n",
       "      <td>cable_spool_fort_3784_3808</td>\n",
       "      <td>Chad just hung his head.</td>\n",
       "      <td>3.2</td>\n",
       "      <td>2.6</td>\n",
       "      <td>2.4</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>5</td>\n",
       "      <td>chad just hung his head</td>\n",
       "      <td>5</td>\n",
       "      <td>train</td>\n",
       "      <td>-0.3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>-0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3883</td>\n",
       "      <td>hotel-california_28834_28854</td>\n",
       "      <td>“I don't know much,”</td>\n",
       "      <td>2.6</td>\n",
       "      <td>2.6</td>\n",
       "      <td>2.6</td>\n",
       "      <td>0.489898</td>\n",
       "      <td>0.489898</td>\n",
       "      <td>0.489898</td>\n",
       "      <td>5</td>\n",
       "      <td>i don t know much</td>\n",
       "      <td>5</td>\n",
       "      <td>train</td>\n",
       "      <td>-0.2</td>\n",
       "      <td>-0.2</td>\n",
       "      <td>-0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>370</td>\n",
       "      <td>detroit_10463_10549</td>\n",
       "      <td>They lack the means to build her back to her f...</td>\n",
       "      <td>3.4</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.6</td>\n",
       "      <td>0.489898</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.489898</td>\n",
       "      <td>5</td>\n",
       "      <td>they lack the means to build her back to her f...</td>\n",
       "      <td>18</td>\n",
       "      <td>train</td>\n",
       "      <td>-0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9790</td>\n",
       "      <td>SemEval_1143</td>\n",
       "      <td>Steelers' Roethlisberger has concussion</td>\n",
       "      <td>2.4</td>\n",
       "      <td>2.4</td>\n",
       "      <td>1.8</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.748331</td>\n",
       "      <td>5</td>\n",
       "      <td>steelers  roethlisberger has concussion</td>\n",
       "      <td>4</td>\n",
       "      <td>train</td>\n",
       "      <td>-0.6</td>\n",
       "      <td>-0.3</td>\n",
       "      <td>-0.3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                            id  \\\n",
       "0        2568    cable_spool_fort_5107_5146   \n",
       "1        2548    cable_spool_fort_3784_3808   \n",
       "2        3883  hotel-california_28834_28854   \n",
       "3         370           detroit_10463_10549   \n",
       "4        9790                  SemEval_1143   \n",
       "\n",
       "                                            sentence  Arousal  Dominance  \\\n",
       "0            Several more boys spewed out after him.      3.2        2.6   \n",
       "1                           Chad just hung his head.      3.2        2.6   \n",
       "2                               “I don't know much,”      2.6        2.6   \n",
       "3  They lack the means to build her back to her f...      3.4        3.0   \n",
       "4            Steelers' Roethlisberger has concussion      2.4        2.4   \n",
       "\n",
       "   Valence  sd.Arousal  sd.Dominance  sd.Valence  freq  \\\n",
       "0      2.6    0.748331      0.489898    0.489898     5   \n",
       "1      2.4    0.400000      0.800000    0.800000     5   \n",
       "2      2.6    0.489898      0.489898    0.489898     5   \n",
       "3      2.6    0.489898      0.000000    0.489898     5   \n",
       "4      1.8    0.800000      0.800000    0.748331     5   \n",
       "\n",
       "                                                 reg  words data_type  \\\n",
       "0            several more boys spewed out after him       7     train   \n",
       "1                           chad just hung his head       5     train   \n",
       "2                                i don t know much        5     train   \n",
       "3  they lack the means to build her back to her f...     18     train   \n",
       "4            steelers  roethlisberger has concussion      4     train   \n",
       "\n",
       "   Valence_reg  Arousal_reg  Dominance_reg  \n",
       "0         -0.2          0.1           -0.2  \n",
       "1         -0.3          0.1           -0.2  \n",
       "2         -0.2         -0.2           -0.2  \n",
       "3         -0.2          0.2            0.0  \n",
       "4         -0.6         -0.3           -0.3  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_v = pd.read_csv('./data_preprocessed_Valence.csv',encoding='utf-16')\n",
    "data_v.head()\n",
    "v_to_name = './pred_v_2.csv'\n",
    "pred_data = data_v.assign(\n",
    "                Valence_pred = pd.Series(v_ary.reshape(-1))\n",
    "            )\n",
    "pred_data.to_csv(v_to_name,encoding='utf-16',sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/ipykernel/__main__.py:2: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    }
   ],
   "source": [
    "model_a_path = './dat_to1/model_Arousal_hidden_dim_8_epoch_50'\n",
    "csv_a_path = './data_preprocessed_Arousal.csv'\n",
    "a_ary = make_prediction(hidden_dim,model_a_path,csv_a_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_a = pd.read_csv('./data_preprocessed_Arousal.csv',encoding='utf-16')\n",
    "a_to_name = './pred_a_2.csv'\n",
    "pred_data = data_a.assign(\n",
    "                Arousal_pred = pd.Series(a_ary.reshape(-1))\n",
    "            )\n",
    "pred_data.to_csv(a_to_name,encoding='utf-16',sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/ipykernel/__main__.py:2: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    }
   ],
   "source": [
    "model_d_path = './dat_to1/model_Dominance_hidden_dim_8_epoch_50'\n",
    "csv_d_path = './data_preprocessed_Dominance.csv'\n",
    "d_ary = make_prediction(hidden_dim,model_d_path,csv_d_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_d = pd.read_csv('./data_preprocessed_Dominance.csv',encoding='utf-16')\n",
    "d_to_name = './pred_d_2.csv'\n",
    "pred_data = data_d.assign(\n",
    "                Dominance_pred = pd.Series(d_ary.reshape(-1))\n",
    "            )\n",
    "pred_data.to_csv(d_to_name,encoding='utf-16',sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/ipykernel/__main__.py:2: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    }
   ],
   "source": [
    "hidden_dim = 8\n",
    "model_v_path = './dat_to1/model_Valence_hidden_dim_8_epoch_50'\n",
    "model_a_path = './dat_to1/model_Arousal_hidden_dim_8_epoch_50'\n",
    "model_d_path = './dat_to1/model_Dominance_hidden_dim_8_epoch_50'\n",
    "v_ary = make_prediction(hidden_dim,model_v_path)\n",
    "a_ary = make_prediction(hidden_dim,model_a_path)\n",
    "d_ary = make_prediction(hidden_dim,model_d_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6917, 1)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a_ary.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_cut = pd.read_csv('./data_cut.csv',encoding='utf-16')\n",
    "csv_name = './pred_vad_1.csv'\n",
    "pred_data = data_cut.assign(\n",
    "                Valence_pred = pd.Series(v_ary.reshape(-1)),\n",
    "                Arousal_pred = pd.Series(a_ary.reshape(-1)),\n",
    "                Dominance_pred = pd.Series(d_ary.reshape(-1))\n",
    "            )\n",
    "pred_data.to_csv(csv_name,encoding='utf-16',sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3000001, 300)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_dim = 6\n",
    "model_path = './dat/model_data_6_epoch_59'\n",
    "model = load_model(hidden_dim, model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "if cuda:\n",
    "    model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/ipykernel/__main__.py:2: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    }
   ],
   "source": [
    "in_dat = [\n",
    "    \"I feel so sorry about that\"\n",
    "]\n",
    "pred_list = []\n",
    "\n",
    "for i in in_dat:\n",
    "    model.zero_grad()\n",
    "    model.hidden = model.init_hidden()\n",
    "    sentence_in = sentence2vec(i)\n",
    "    y = model(sentence_in)[-1,:]\n",
    "    if cuda:\n",
    "        y = y.cpu()\n",
    "    pred_list.append(y.detach().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_list = np.array(pred_list)\n",
    "pred_list = pred_list*2 + 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Valence  ,Arousal  ,Dominance]\n",
      "[2.5193458 3.1973207 2.9886205]  I feel so sorry about that\n"
     ]
    }
   ],
   "source": [
    "pred_list = list(pred_list)\n",
    "print(\"[Valence  ,Arousal  ,Dominance]\")\n",
    "for sentence,vad in zip(in_dat,pred_list):\n",
    "    print(str(vad)+\"  \"+sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_pytorch_p36)",
   "language": "python",
   "name": "conda_pytorch_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
