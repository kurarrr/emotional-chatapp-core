{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "from nltk.corpus import wordnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10358 10325 10142\n"
     ]
    }
   ],
   "source": [
    "# dataのload\n",
    "data_sentence = pd.read_table('./Emobank-master/corpus/raw.tsv')\n",
    "data_vad = pd.read_table('./Emobank-master/corpus/reader.tsv')\n",
    "data_merged = pd.merge(data_sentence,data_vad,on='id')\n",
    "print(len(data_sentence),len(data_vad),len(data_merged))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "ser = data_merged['sentence']\n",
    "\n",
    "# 数字を全て0に\n",
    "p_num = re.compile(r'[0-9]+')\n",
    "ser = ser.apply(lambda x:p_num.sub(\"0\",x))\n",
    "\n",
    "# urlをremove \n",
    "p_url = re.compile(r'http[a-zA-Z0-9\\!\\#\\$\\%\\&\\'\\*\\+\\-\\.\\^_\\`\\|\\~\\:]*')\n",
    "ser = ser.apply(lambda x:p_url.sub(\" \",x))\n",
    "\n",
    "# replace .,! -> \\s\n",
    "ser = ser.apply(lambda x: x.replace(\".\",\" \").replace(\",\",\" \").replace(\"!\",\" \").replace(\"'\",\" \").replace(\"\\\"\",\" \").replace(\"“\",\" \").replace(\"”\",\" \"))\n",
    "\n",
    "# lowerに\n",
    "ser = ser.apply(lambda x:x.lower())\n",
    "\n",
    "data_preprocessed = data_merged.assign(\n",
    "    reg = ser\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from nltk import word_tokenize\n",
    "# sent = \"This is my text, this is a nice way  to input text. I'm angry\"\n",
    "# word_tokenize(sent)\n",
    "data_preprocessed = data_preprocessed.assign(\n",
    "    words = data_preprocessed.apply(lambda x: len(word_tokenize(x['reg'])), axis=1)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_preprocessed.to_csv('data_preprocessed.csv',encoding=\"utf-16\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>sentence</th>\n",
       "      <th>Arousal</th>\n",
       "      <th>Dominance</th>\n",
       "      <th>Valence</th>\n",
       "      <th>sd.Arousal</th>\n",
       "      <th>sd.Dominance</th>\n",
       "      <th>sd.Valence</th>\n",
       "      <th>freq</th>\n",
       "      <th>reg</th>\n",
       "      <th>words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Acephalous-Cant-believe_4_47</td>\n",
       "      <td>I can't believe I wrote all that last year.</td>\n",
       "      <td>3.4</td>\n",
       "      <td>3.2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5</td>\n",
       "      <td>i can t believe i wrote all that last year</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Acephalous-Cant-believe_83_354</td>\n",
       "      <td>Because I've been grading all damn day and am ...</td>\n",
       "      <td>3.2</td>\n",
       "      <td>3.2</td>\n",
       "      <td>2.8</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>5</td>\n",
       "      <td>because i ve been grading all damn day and am ...</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Acephalous-Cant-believe_355_499</td>\n",
       "      <td>However, when I started looking through my arc...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.2</td>\n",
       "      <td>3.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.489898</td>\n",
       "      <td>5</td>\n",
       "      <td>however  when i started looking through my arc...</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Acephalous-Cant-believe_500_515</td>\n",
       "      <td>What do I mean?</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5</td>\n",
       "      <td>what do i mean?</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Acephalous-Cant-believe_517_626</td>\n",
       "      <td>The posts I consider foundational to my curren...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5</td>\n",
       "      <td>the posts i consider foundational to my curren...</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                id  \\\n",
       "0     Acephalous-Cant-believe_4_47   \n",
       "1   Acephalous-Cant-believe_83_354   \n",
       "2  Acephalous-Cant-believe_355_499   \n",
       "3  Acephalous-Cant-believe_500_515   \n",
       "4  Acephalous-Cant-believe_517_626   \n",
       "\n",
       "                                            sentence  Arousal  Dominance  \\\n",
       "0        I can't believe I wrote all that last year.      3.4        3.2   \n",
       "1  Because I've been grading all damn day and am ...      3.2        3.2   \n",
       "2  However, when I started looking through my arc...      3.0        3.2   \n",
       "3                                    What do I mean?      3.0        3.0   \n",
       "4  The posts I consider foundational to my curren...      3.0        3.0   \n",
       "\n",
       "   Valence  sd.Arousal  sd.Dominance  sd.Valence  freq  \\\n",
       "0      3.0         0.8           0.4    0.000000     5   \n",
       "1      2.8         0.4           0.4    0.400000     5   \n",
       "2      3.4         0.0           0.4    0.489898     5   \n",
       "3      3.0         0.0           0.0    0.000000     5   \n",
       "4      3.0         0.0           0.0    0.000000     5   \n",
       "\n",
       "                                                 reg  words  \n",
       "0        i can t believe i wrote all that last year      10  \n",
       "1  because i ve been grading all damn day and am ...     49  \n",
       "2  however  when i started looking through my arc...     26  \n",
       "3                                    what do i mean?      5  \n",
       "4  the posts i consider foundational to my curren...     18  "
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_preprocessed.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>Valence</th>\n",
       "      <th>sentence</th>\n",
       "      <th>sd.Valence</th>\n",
       "      <th>reg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Acephalous-Cant-believe_4_47</td>\n",
       "      <td>3.0</td>\n",
       "      <td>I can't believe I wrote all that last year.</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>i can t believe i wrote all that last year</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Acephalous-Cant-believe_83_354</td>\n",
       "      <td>2.8</td>\n",
       "      <td>Because I've been grading all damn day and am ...</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>because i ve been grading all damn day and am ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Acephalous-Cant-believe_355_499</td>\n",
       "      <td>3.4</td>\n",
       "      <td>However, when I started looking through my arc...</td>\n",
       "      <td>0.489898</td>\n",
       "      <td>however  when i started looking through my arc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Acephalous-Cant-believe_500_515</td>\n",
       "      <td>3.0</td>\n",
       "      <td>What do I mean?</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>what do i mean?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Acephalous-Cant-believe_517_626</td>\n",
       "      <td>3.0</td>\n",
       "      <td>The posts I consider foundational to my curren...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>the posts i consider foundational to my curren...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                id  Valence  \\\n",
       "0     Acephalous-Cant-believe_4_47      3.0   \n",
       "1   Acephalous-Cant-believe_83_354      2.8   \n",
       "2  Acephalous-Cant-believe_355_499      3.4   \n",
       "3  Acephalous-Cant-believe_500_515      3.0   \n",
       "4  Acephalous-Cant-believe_517_626      3.0   \n",
       "\n",
       "                                            sentence  sd.Valence  \\\n",
       "0        I can't believe I wrote all that last year.    0.000000   \n",
       "1  Because I've been grading all damn day and am ...    0.400000   \n",
       "2  However, when I started looking through my arc...    0.489898   \n",
       "3                                    What do I mean?    0.000000   \n",
       "4  The posts I consider foundational to my curren...    0.000000   \n",
       "\n",
       "                                                 reg  \n",
       "0        i can t believe i wrote all that last year   \n",
       "1  because i ve been grading all damn day and am ...  \n",
       "2  however  when i started looking through my arc...  \n",
       "3                                    what do i mean?  \n",
       "4  the posts i consider foundational to my curren...  "
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_valence = pd.concat(\n",
    "    [\n",
    "        data_preprocessed['id'],data_preprocessed['Valence'],data_preprocessed['sentence'],\n",
    "        data_preprocessed['sd.Valence'],data_preprocessed['reg']\n",
    "    ],\n",
    "    axis=1\n",
    ")\n",
    "data_valence.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3974561230526523\n"
     ]
    }
   ],
   "source": [
    "num = len(data_preprocessed[\n",
    "    (data_preprocessed['Valence']>=2.8)&(data_preprocessed['Valence']<=3.2)\n",
    "    &(data_preprocessed['Arousal']>=2.8)&(data_preprocessed['Arousal']<=3.2)\n",
    "    &(data_preprocessed['Dominance']>=2.8)&(data_preprocessed['Dominance']<=3.2)\n",
    "])\n",
    "print(num / len(data_preprocessed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "vad_mask = (data_preprocessed['Valence']>=2.8)&(data_preprocessed['Valence']<=3.2)\\\n",
    "          &(data_preprocessed['Arousal']>=2.8)&(data_preprocessed['Arousal']<=3.2)\\\n",
    "          &(data_preprocessed['Dominance']>=2.8)&(data_preprocessed['Dominance']<=3.2)\n",
    "data_1 = data_preprocessed[vad_mask]\n",
    "data_2 = data_preprocessed[~(vad_mask)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data_preprocessed) == len(data_1) + len(data_2) # confirm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.19995038451997024"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_use,data_no_use = train_test_split(data_1, test_size=0.8)\n",
    "len(data_use)/len(data_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.620193255768093\n",
      "0.44311117536504263\n",
      "0.6566752119897457\n",
      "0.49660257336995806\n"
     ]
    }
   ],
   "source": [
    "data_cut = pd.concat([data_use,data_2])\n",
    "print(len(data_preprocessed[(data_preprocessed['Valence']>=2.8)&(data_preprocessed['Valence']<=3.2)])/len(data_preprocessed))\n",
    "print(len(data_cut[(data_cut['Valence']>=2.8)&(data_cut['Valence']<=3.2)])/len(data_cut))\n",
    "print(len(data_preprocessed[(data_preprocessed['Arousal']>=2.8)&(data_preprocessed['Arousal']<=3.2)])/len(data_preprocessed))\n",
    "print(len(data_cut[(data_cut['Arousal']>=2.8)&(data_cut['Arousal']<=3.2)])/len(data_cut))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, dev_test = train_test_split(data_cut,test_size=0.4)\n",
    "dev, test = train_test_split(dev_test,test_size=0.25)\n",
    "# train/dev/test = 6/3/1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.assign(data_type='train')\n",
    "dev = dev.assign(data_type='dev')\n",
    "test = test.assign(data_type='test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_cut = pd.concat([train,dev,test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5999710857308082\n",
      "0.2999855428654041\n"
     ]
    }
   ],
   "source": [
    "print(len(data_cut[data_cut['data_type']=='train'])/len(data_cut))\n",
    "print(len(data_cut[data_cut['data_type']=='dev'])/len(data_cut))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=1\n",
    "b=5\n",
    "data_cut = data_cut.assign(\n",
    "    Valence_reg = data_cut.apply(lambda x: 2*(x['Valence']-a)/(b-a)-1, axis=1),\n",
    "    Arousal_reg = data_cut.apply(lambda x: 2*(x['Arousal']-a)/(b-a)-1, axis=1),\n",
    "    Dominance_reg = data_cut.apply(lambda x: 2*(x['Dominance']-a)/(b-a)-1, axis=1)\n",
    ")\n",
    "# [-1,1]で正規化\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>sentence</th>\n",
       "      <th>Arousal</th>\n",
       "      <th>Dominance</th>\n",
       "      <th>Valence</th>\n",
       "      <th>sd.Arousal</th>\n",
       "      <th>sd.Dominance</th>\n",
       "      <th>sd.Valence</th>\n",
       "      <th>freq</th>\n",
       "      <th>reg</th>\n",
       "      <th>words</th>\n",
       "      <th>data_type</th>\n",
       "      <th>Valence_reg</th>\n",
       "      <th>Arousal_reg</th>\n",
       "      <th>Dominance_reg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>448</th>\n",
       "      <td>detroit_15065_15155</td>\n",
       "      <td>Otters in post-Valdez Alaska are clawing their...</td>\n",
       "      <td>3.4</td>\n",
       "      <td>3.4</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.019804</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.894427</td>\n",
       "      <td>5</td>\n",
       "      <td>otters in post-valdez alaska are clawing their...</td>\n",
       "      <td>13</td>\n",
       "      <td>train</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6658</th>\n",
       "      <td>20000410_nyt-NEW_47_77</td>\n",
       "      <td>By Scott Montgomery Washington</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>by scott montgomery washington</td>\n",
       "      <td>4</td>\n",
       "      <td>train</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3528</th>\n",
       "      <td>hotel-california_12145_12198</td>\n",
       "      <td>I would immerse myself in new virtual reality ...</td>\n",
       "      <td>3.4</td>\n",
       "      <td>3.2</td>\n",
       "      <td>3.2</td>\n",
       "      <td>0.489898</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>5</td>\n",
       "      <td>i would immerse myself in new virtual reality ...</td>\n",
       "      <td>9</td>\n",
       "      <td>train</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9570</th>\n",
       "      <td>SemEval_918</td>\n",
       "      <td>Barbaro's legacy: saving other horses</td>\n",
       "      <td>3.4</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.4</td>\n",
       "      <td>0.489898</td>\n",
       "      <td>0.632456</td>\n",
       "      <td>0.489898</td>\n",
       "      <td>5</td>\n",
       "      <td>barbaro s legacy: saving other horses</td>\n",
       "      <td>7</td>\n",
       "      <td>train</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5871</th>\n",
       "      <td>118CWL050_3607_3658</td>\n",
       "      <td>When you give to Big Sisters, you can get 50% ...</td>\n",
       "      <td>3.6</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.4</td>\n",
       "      <td>0.489898</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.489898</td>\n",
       "      <td>5</td>\n",
       "      <td>when you give to big sisters  you can get 0% b...</td>\n",
       "      <td>12</td>\n",
       "      <td>train</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                id  \\\n",
       "448            detroit_15065_15155   \n",
       "6658        20000410_nyt-NEW_47_77   \n",
       "3528  hotel-california_12145_12198   \n",
       "9570                   SemEval_918   \n",
       "5871           118CWL050_3607_3658   \n",
       "\n",
       "                                               sentence  Arousal  Dominance  \\\n",
       "448   Otters in post-Valdez Alaska are clawing their...      3.4        3.4   \n",
       "6658                     By Scott Montgomery Washington      2.0        3.0   \n",
       "3528  I would immerse myself in new virtual reality ...      3.4        3.2   \n",
       "9570              Barbaro's legacy: saving other horses      3.4        3.0   \n",
       "5871  When you give to Big Sisters, you can get 50% ...      3.6        3.0   \n",
       "\n",
       "      Valence  sd.Arousal  sd.Dominance  sd.Valence  freq  \\\n",
       "448       2.0    1.019804      0.800000    0.894427     5   \n",
       "6658      3.0    1.000000      0.000000    0.000000     2   \n",
       "3528      3.2    0.489898      0.400000    0.400000     5   \n",
       "9570      3.4    0.489898      0.632456    0.489898     5   \n",
       "5871      3.4    0.489898      0.000000    0.489898     5   \n",
       "\n",
       "                                                    reg  words data_type  \\\n",
       "448   otters in post-valdez alaska are clawing their...     13     train   \n",
       "6658                     by scott montgomery washington      4     train   \n",
       "3528  i would immerse myself in new virtual reality ...      9     train   \n",
       "9570              barbaro s legacy: saving other horses      7     train   \n",
       "5871  when you give to big sisters  you can get 0% b...     12     train   \n",
       "\n",
       "      Valence_reg  Arousal_reg  Dominance_reg  \n",
       "448          -0.5          0.2            0.2  \n",
       "6658          0.0         -0.5            0.0  \n",
       "3528          0.1          0.2            0.1  \n",
       "9570          0.2          0.2            0.0  \n",
       "5871          0.2          0.3            0.0  "
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_cut.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_cut.to_csv('data_cut.csv',encoding=\"utf-16\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(data_cut.ix[1074]['sentence'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_pytorch_p36)",
   "language": "python",
   "name": "conda_pytorch_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
